{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PN = '../data/taobao-comment/pn.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = pd.read_excel('../data/taobao-comment/neg.xls', header=None, index=None)\n",
    "pos = pd.read_excel('../data/taobao-comment/pos.xls', header=None, index=None)  # 读取训练语料完毕\n",
    "\n",
    "neg['text'] = neg[0]\n",
    "pos['text'] = pos[0]\n",
    "pos['mark'] = 1\n",
    "neg['mark'] = 0  # 给训练语料贴上标签\n",
    "\n",
    "pn = pd.concat([pos, neg], ignore_index=True)  # 合并语料\n",
    "pn = pn[['text', 'mark']]\n",
    "permutation = np.random.permutation(pn.shape[0])\n",
    "pn = pn.iloc[permutation]\n",
    "print(pn.head(5))\n",
    "pn.to_csv('../data/taobao-comment/pn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = pd.read_csv(PATH_PN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  mark\n0    用起来还不错，本人还有几张2000-100 1000-50 东券要的加qq 673946022     1\n1  2006年12月16号住了一晚，因为看过ctrip的住户点评区，直到比较吵，专门要了一间8楼...     0\n2  1.机身采用喷漆，很有质感,手感也很不错的.2.屏幕颜色过渡柔和，显示效果细腻.3.按键面积...     1\n3  完美屏，第一次买NOTEBOOK，手神还不错嘛DDR3的条子，蓝牙，WIFI，你想得到的它帮你配齐     1\n4             所谓升职，过程中掺杂了太多的勾心斗角，我自己不喜欢这样的风格，纯属个人观点。     0\n"
     ]
    }
   ],
   "source": [
    "print(pn.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.794 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "pn['words'] = pn['text'].apply(lambda x: list(jieba.cut(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [用, 起来, 还, 不错, ，, 本人, 还有, 几张, 2000, -, 100,  ,...\n1    [2006, 年, 12, 月, 16, 号, 住, 了, 一晚, ，, 因为, 看过, c...\n2    [1, ., 机身, 采用, 喷漆, ，, 很, 有, 质感, ,, 手感, 也, 很, 不...\n3    [完美, 屏, ，, 第一次, 买, NOTEBOOK, ，, 手神, 还, 不错, 嘛, ...\n4    [所谓, 升职, ，, 过程, 中, 掺杂, 了, 太, 多, 的, 勾心斗角, ，, 我,...\nName: words, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(pn['words'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word2vec = Word2Vec(pn['words'], size=64, window=5, min_count=5, workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.70475632, -3.13468909,  0.46770158,  1.2176801 , -0.05716988,\n       -1.11763108, -1.04645038,  0.18612705,  0.2793124 ,  1.89003778,\n       -0.76277429,  0.52214617,  0.19929956, -0.42592835, -0.07852405,\n        0.24108826, -0.36993554,  2.08380532,  0.04404699,  0.29671344,\n       -1.34178758, -0.7705968 ,  1.45506966, -0.03248395, -0.71018058,\n        0.92320287,  0.36943343,  0.79457504,  0.33891708,  1.64407682,\n        2.19278812, -1.15802133, -0.62688446,  0.3780694 ,  1.39938617,\n       -0.76018089, -1.89643824,  0.45279738,  0.27944747,  0.2496397 ,\n        1.61094046,  0.21132395, -1.60298753, -0.82045156,  0.3762545 ,\n        3.25001216,  0.28707173,  0.8503629 ,  0.56816649, -1.48735416,\n       -0.51098305, -1.30979955,  0.78904366,  1.09420216, -0.12752515,\n       -0.53096753, -1.78223431, -1.16513705, -0.31322289, -0.2370282 ,\n        0.90583128, -1.16366589, -0.22632426, -1.51436877], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_word2vec['我']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict([(k, v.index+1) for k, v in model_word2vec.wv.vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.keyedvectors.KeyedVectors object at 0x7fc79117f908>\n"
     ]
    }
   ],
   "source": [
    "print(model_word2vec.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in vocab:\n",
    "    if vocab[i] == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(vocab, open('../data/taobao-comment/tokenizer', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = defaultdict(lambda: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer['我']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.update(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [tokenizer[x] for x in tokenizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(idx), len(set(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
